{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "655bd22e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import datetime as dt\n",
    "from hdfs import InsecureClient\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "client = InsecureClient('http://localhost:9870', user='big')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ab9ab4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_std_day(befor_day):   \n",
    "    x = dt.datetime.now() - dt.timedelta(befor_day)\n",
    "    year = x.year\n",
    "    month = x.month if x.month >= 10 else '0'+ str(x.month)\n",
    "    day = x.day if x.day >= 10 else '0'+ str(x.day)  \n",
    "    return str(year)+ '-' +str(month)+ '-' +str(day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "925bac87",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ac12033a",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'coalesce'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [6]\u001b[0m, in \u001b[0;36m<cell line: 76>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     62\u001b[0m result \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     63\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmeta\u001b[39m\u001b[38;5;124m'\u001b[39m:{\n\u001b[1;32m     64\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdesc\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m미세먼지\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     72\u001b[0m    \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m'\u001b[39m:data\n\u001b[1;32m     73\u001b[0m }\n\u001b[1;32m     74\u001b[0m \u001b[38;5;66;03m# client.write(file_dir+file_name, json.dumps(data, ensure_ascii=False), encoding='utf-8')\u001b[39;00m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;66;03m# data.write.csv(\"hdfs:/themapark/dust/\")\u001b[39;00m\n\u001b[0;32m---> 76\u001b[0m \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcoalesce\u001b[49m(\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39m\\\n\u001b[1;32m     77\u001b[0m     write\u001b[38;5;241m.\u001b[39m\\\n\u001b[1;32m     78\u001b[0m     \u001b[38;5;28mformat\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcom.databricks.spark.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39m\\\n\u001b[1;32m     79\u001b[0m     option(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mheader\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrue\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39m\\\n\u001b[1;32m     80\u001b[0m     save(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/data/output.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'coalesce'"
     ]
    }
   ],
   "source": [
    "file_dir = '/themapark/dust/'\n",
    "file_name = 'dust' + cal_std_day(1) + '.json'\n",
    "base_url=['4129000000','1171000000','4146100000','4211000000','1121500000']\n",
    "cols=['지역','날짜','미세먼지','초미세먼지']\n",
    "rows_list = []\n",
    "for l in base_url:\n",
    "    url = 'https://www.kr-weathernews.com/mv3/if/pm.fcgi?region={}'.format(l)\n",
    "    response = requests.get(url)\n",
    "    res = response.json()\n",
    "    rows = []\n",
    "    day = cal_std_day(0)\n",
    "    #지역\n",
    "    if l == '4129000000':\n",
    "        rows.append('과천')\n",
    "    elif l =='1171000000':\n",
    "        rows.append('송파')\n",
    "    elif l =='4146100000':\n",
    "        rows.append('용인')\n",
    "    elif l =='4211000000':\n",
    "        rows.append('춘천')\n",
    "    elif l =='1121500000':\n",
    "        rows.append('광진')        \n",
    "    #날짜\n",
    "    rows.append(day)\n",
    "    #미세먼지\n",
    "    rows.append(res['pm']['history'][-1]['pm10'])\n",
    "    #초미세먼지\n",
    "    rows.append(res['pm']['history'][-1]['pm25'])\n",
    "    rows_list.append(rows)\n",
    "    for i in range(0,10):\n",
    "        rows = []\n",
    "        #지역\n",
    "        if l == '4129000000':\n",
    "            rows.append('과천')\n",
    "        elif l =='1171000000':\n",
    "            rows.append('송파')\n",
    "        elif l =='4146100000':\n",
    "            rows.append('용인')\n",
    "        elif l =='4211000000':\n",
    "            rows.append('춘천')\n",
    "        elif l =='1121500000':\n",
    "            rows.append('광진')    \n",
    "\n",
    "        #날짜\n",
    "        rows.append(str(res['pm']['forcast']['daily'][i]['year']) +'-'+ str(res['pm']['forcast']['daily'][i]['mon']) +'-' + str(res['pm']['forcast']['daily'][i]['day']))\n",
    "#         #년\n",
    "#         rows.append(res['pm']['forcast']['daily'][i]['year'])\n",
    "#         #월\n",
    "#         rows.append(res['pm']['forcast']['daily'][i]['mon'])\n",
    "#         #일\n",
    "#         rows.append(res['pm']['forcast']['daily'][i]['day'])\n",
    "        #미세먼지\n",
    "        rows.append(res['pm']['forcast']['daily'][i]['pm10'])\n",
    "        #초미세먼지\n",
    "        rows.append(res['pm']['forcast']['daily'][i]['pm25'])\n",
    "        rows_list.append(rows)\n",
    "        \n",
    "for rows in rows_list:\n",
    "    tmp=dict(zip(cols,rows))\n",
    "    data.append(tmp)\n",
    "    \n",
    "result = {\n",
    "    'meta':{\n",
    "        'desc':'미세먼지',\n",
    "        'cols':{\n",
    "            '지역':'지역',\n",
    "            '날짜':'날짜',\n",
    "            '미세먼지':'미세먼지',\n",
    "            '초미세먼지':'초미세먼지'\n",
    "        },\n",
    "    },\n",
    "   'data':data\n",
    "}\n",
    "# client.write(file_dir+file_name, json.dumps(data, ensure_ascii=False), encoding='utf-8')\n",
    "# data.write.csv(\"hdfs:/themapark/dust/\")\n",
    "data.coalesce(1).\\\n",
    "    write.\\\n",
    "    format(\"com.databricks.spark.csv\").\\\n",
    "    option(\"header\", \"true\").\\\n",
    "    save(\"/data/output.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3b9078d3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "int"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(int(res['pm']['history'][-1]['pm10']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6a5d6b3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "int"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(res['pm']['forcast']['daily'][i]['pm10'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1d4678a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2022"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res['pm']['forcast']['daily'][i]['year']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
